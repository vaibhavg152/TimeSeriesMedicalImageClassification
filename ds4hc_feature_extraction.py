# -*- coding: utf-8 -*-
"""DS4HC-Feature_extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15Qmryfx9NAfRa5zZ_eoXeZf7vtZJz-2w
"""

# !pip install transformers
!pip install torchxrayvision

from google.colab import drive
drive.mount('/content/gdrive')

!tar -xzf /content/gdrive/MyDrive/Colab\ Notebooks/images.tar.gz

import skimage
import torch
import torch.nn.functional as F
import torchvision
import torchvision.transforms

import torchxrayvision as xrv
from tqdm.notebook import tqdm
from glob import glob
from time import time
import numpy as np

# from transformers import ViTImageProcessor, ViTModel
from PIL import Image
from tqdm.notebook import tqdm

import pandas as pd

# images = sorted(glob('/content/ms_cxr_t_images/*'))[:23]
# print(len(images))

# processor = ViTImageProcessor.from_pretrained('nickmuchi/vit-finetuned-chest-xray-pneumonia')
# model = ViTModel.from_pretrained('nickmuchi/vit-finetuned-chest-xray-pneumonia')

# features_vit = []
# for image_path in tqdm(images):
#   image = Image.open(image_path)
#   # Convert to RGB
#   rgbimg = Image.new("RGB", image.size)
#   rgbimg.paste(image)
#   image = rgbimg

#   inputs = processor(images=image, return_tensors="pt")
#   outputs = model(**inputs)

#   last_hidden_states = outputs.last_hidden_state.unsqueeze(0).to(torch.float16).detach()
#   if len(features_vit) == 0:
#     features_vit = last_hidden_states
#   else:
#     features_vit = torch.cat((features_vit, last_hidden_states), 0)

# features_vit.dtype

# print(features_vit.squeeze().shape)

# import csv
# with open('features_vit.csv', 'w+') as f:
#   writer = csv.writer(f)
#   d = list(zip(images, features_vit.squeeze(0).detach().numpy()))
#   # np.savetxt(f, features_vit.squeeze(0).numpy())
#   writer.writerows(d)

# # import json
# # d = dict(zip(images, features_vit.squeeze().tolist()))
# # with open(f'features_vit.json', 'w+') as f:
# #   json.dump(fp=f, obj=d, indent=2)

"""  **X-Ray Vision models**

Change the variable model_name and run all the cells below to get the features in "features_model_name.json". Download it
"""

# model_name = "densenet121-res224-rsna"
# model = xrv.models.get_model(model_name)

# features = []
# X = []

# transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop()])

# images = sorted(glob('/content/ms_cxr_t_images/*'))
# print(len(images))

# for img_path in tqdm(images):
#   img = skimage.io.imread(img_path)
#   img = xrv.datasets.normalize(img, 255)
#   if len(img.shape) < 2:
#       print("error, dimension lower than 2 for image")
#   if len(img.shape) > 2:
#     img = img[:, :, 0]
#   img = img[None, :, :]
#   img = transform(img)
#   img = torch.from_numpy(img).unsqueeze(0)
#   img = xrv.models.fix_resolution(img, 224, model)
#   if len(X) == 0:
#     X = img
#   else:
#     X = torch.cat((X, img), dim=0)
# print(X.shape)

# s = time()

# D = 200
# with torch.no_grad():
#   features = model.features2(X[:D])
#   for i in tqdm(range(D, len(X), D)):
#     features = torch.cat( (features, model.features2(X[i: (i+D)]) ), dim=0)
#   #  out = model.classifier(features)
#   #    preds = torch.sigmoid(out).cpu()
#   #     output = {
#   #         k: float(v)
#   #         for k, v in zip(xrv.datasets.default_pathologies, preds[0].detach().numpy())
#   #     }
#   # print(output)
# print(features.shape, time()-s)

# print(features.shape)

# import json
# d = dict(zip(images, features.tolist()))
# with open(f'features_{model_name}.json', 'w+') as f:
#   json.dump(fp=f, obj=d, indent=2)

feature_extractor = "densenet121-res224-chex"

import json
with open(f'features_{feature_extractor}.json') as f:
  data = json.load(f)

images = list(data.keys())
features = torch.Tensor(list(data.values()))

features.shape

"""Train the model"""

from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor

class CXRT_Dataset_2(Dataset):
  DISEASE_NAMES = ['edema', 'consolidation', 'pleural_effusion', 'pneumothorax', 'pneumonia']
  def __init__(self, annotations_file, features_file, disease_name):
        assert disease_name in self.DISEASE_NAMES, "valid disease names: " + " ".join(self.DISEASE_NAMES)
        self.df = pd.read_csv(annotations_file)
        self.df = self.df[~self.df[f'{disease_name}_progression'].isna()]
        self.image1 = self.df.previous_dicom_id.to_numpy()
        self.image2 = self.df.dicom_id.to_numpy()
        
        self.image1 = [p.split('/')[-1] for p in self.image1]
        self.image2 = [p.split('/')[-1] for p in self.image2]
        self.df[f'{disease_name}_progression'].replace({'worsening': 1, 'stable': 0, 'improving': 2}, inplace=True)
        
        self.labels = torch.LongTensor(self.df[f'{disease_name}_progression'].to_list())
        
        with open(features_file) as f:
          data = json.load(f)
          self.image_names = [d.split('/')[-1] for d in data.keys()]
          self.in_features = torch.Tensor(list(data.values()))

  def __len__(self):
        return self.df.shape[0]

  def __getitem__(self, idx):
        label = self.labels[idx]

        image1 = self.in_features[self.image_names.index(self.image1[idx]+'.jpg')]
        image2 = self.in_features[self.image_names.index(self.image2[idx]+'.jpg')]
        return image1, image2, label

import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

torch.manual_seed(10)

annotations_file = glob('/content/*image*.csv')[0]
BATCH_SIZE = 8


class Net(nn.Module):
    def __init__(self, in_features, hidden_features, num_classes):
        super().__init__()
        self.lin2 = nn.Linear(in_features=2*in_features, out_features=hidden_features)
        self.lin3 = nn.Linear(in_features=hidden_features, out_features=num_classes)
        
    def forward(self, x1, x2):
        x = torch.cat( (x1, x2), dim=1)
        x = F.relu(self.lin2(x))
        x = F.log_softmax(self.lin3(x))
        return x

# net = Net(features.shape[-1], 2048, num_classes=3)
# net.cuda()


class Model1(Net):
    BATCH_SIZE = 8
    def __init__(self, disease_name, annotations_file, feature_extractor, hidden_features=2048):

      dataset = CXRT_Dataset_1(annotations_file, f'features_{feature_extractor}.json', disease_name)
      self.in_features = dataset.in_features.shape[-1] 

      super().__init__(self.in_features, hidden_features, num_classes=3)

      trainset, testset = torch.utils.data.random_split(dataset, [0.8, 0.2])

      self.trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,
                                                shuffle=True, num_workers=2)

      self.testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,
                                              shuffle=False, num_workers=2)
      self.criterion = nn.CrossEntropyLoss()
      self.optimizer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)

    def train(self, num_epochs=50):
      for epoch in tqdm(range(num_epochs)):  # loop over the dataset multiple times
          running_loss = 0.0
          for i, data in enumerate(self.trainloader, 0):
              image1, image2, labels = data

              # zero the parameter gradients
              self.optimizer.zero_grad()

              outputs = self.forward(image1, image2)
              loss = self.criterion(outputs, labels)
              loss.backward()
              self.optimizer.step()

              running_loss += loss.item()
      print('Finished Training')
    
    def test(self):
      num_correct, total = 0, 0
      for i, data in tqdm(enumerate(self.testloader, 0)):
          image1, image2, labels = data
          outputs = net(image1, image2)
          preds = np.argmax(outputs.detach().numpy(), axis=1)
          labels = labels.detach().numpy()
          num_correct += (preds==labels).sum()
          total += len(labels)
          # print(preds, labels)
      print(num_correct, total, 100*num_correct/total)

# net = Net(features.shape[-1], 2048, num_classes=3)

# batch_size = 8
# dataset = CXRT_Dataset(glob('/content/*image*.csv')[0], f'features_{model_name}.json')
# trainset, testset = torch.utils.data.random_split(dataset, [0.8, 0.2])

# torch.utils.data.random_split
# trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
#                                           shuffle=True, num_workers=2)

# testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
#                                          shuffle=False, num_workers=2)
# len(trainloader), len(testloader)

# dataset.df.shape

for disease in CXRT_Dataset_1.DISEASE_NAMES:
  net = Model1(disease, annotations_file, feature_extractor, 2048)
  print(disease)
  net.train()
  net.test()

import pandas as pd
from glob import glob
df = pd.read_csv(glob('/content/*image*.csv')[0])
df['label'] = 'blah'
df.label[~df.edema_progression.isna()] = df.edema_progression[~df.edema_progression.isna()]
print(df.label.value_counts())
print(df.edema_progression.value_counts())
df.label[~df.consolidation_progression.isna()] = df.consolidation_progression[~df.consolidation_progression.isna()]
print(df.label.value_counts())
print(df.consolidation_progression.value_counts())

label_cols = [c for c in df.columns if 'progression' in c]
for i in range(5):
	for j in range(i+1, 5):
		col1, col2 = label_cols[i], label_cols[j]
		print(df[(~df[col1].isna()) & (~df[col2].isna())].shape, '\t', col1, '\t', col2)

